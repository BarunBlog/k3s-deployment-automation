name: Apply Kubernetes Manifests

on:
  workflow_run:
    workflows: ["K3s deployment using Ansible"]
    types:
      - completed

  workflow_dispatch:

jobs:
  apply_manifests:
    if: |
      github.event_name == 'workflow_dispatch' ||
      github.event.workflow_run.conclusion == 'success'

    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-southeast-1

      - name: Pulumi login
        env:
          PULUMI_ACCESS_TOKEN: ${{ secrets.PULUMI_ACCESS_TOKEN }}
        run: pulumi login

      - name: Pulumi stack select
        run: pulumi stack select dev --cwd infra

      - name: Pulumi refresh
        run: pulumi refresh --yes --cwd infra

      - name: Save Pulumi outputs
        id: pulumi_outputs
        run: |
          GIT_RUNNER_IP=$(pulumi stack output git_runner_public_ip --cwd infra)
          MASTER_NODE_IP=$(pulumi stack output master_private_ip --cwd infra)
          echo "GIT_RUNNER_IP=$GIT_RUNNER_IP" >> $GITHUB_ENV
          echo "MASTER_NODE_IP=$MASTER_NODE_IP" >> $GITHUB_ENV
        env:
          PULUMI_ACCESS_TOKEN: ${{ secrets.PULUMI_ACCESS_TOKEN }}

      - name: Set up SSH agent
        uses: webfactory/ssh-agent@v0.5.3
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: SSH into GitHub Runner and deploy manifests
        run: |
          ssh -o StrictHostKeyChecking=no ubuntu@${{ env.GIT_RUNNER_IP }} << 'EOF'
            
            # Print commands to debug issues
            set -ex
          
            # Define cleanup function
            cleanup() {
              echo "Cleaning up kubeconfig..."
              rm -f ~/.kube/config
            }
          
            # Execute cleanup on exit (normal or error)
            trap cleanup EXIT
          
            # Install kubectl (Needed for raw manifests and Helm)
            if ! command -v kubectl &> /dev/null; then
              echo "Installing kubectl..."
              curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
              sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
            fi
            
            # Fix Key Permissions
            chmod 600 ~/.ssh/my-key-pair.pem
            
            # Get Kubeconfig from Master Node
            # We use SSH from the Runner to the Master to grab the file
            ssh -n -o StrictHostKeyChecking=no -i ~/.ssh/my-key-pair.pem ubuntu@${{ env.MASTER_NODE_IP }} "sudo cat /etc/rancher/k3s/k3s.yaml" > k3s-temp.yaml
            
            # Update the API Server address in the config
            # Replace 127.0.0.1 with the actual Private IP of the Master Node
            sed -i "s/127.0.0.1/${{ env.MASTER_NODE_IP }}/g" k3s-temp.yaml
            
            # Move it to the default location for kubectl/helm
            mkdir -p ~/.kube
            mv k3s-temp.yaml ~/.kube/config
            chmod 600 ~/.kube/config
            
            # Verify connection
            kubectl get nodes
            
            # Create a working directory for infra repo
            if [ ! -d "ecommerce-kubernetes-infra" ]; then
              git clone https://github.com/BarunBlog/ecommerce-kubernetes-infra.git
              cd ecommerce-kubernetes-infra
            else
              cd ecommerce-kubernetes-infra
              git pull
            fi

            # Install Helm if not installed
            if ! command -v helm &> /dev/null
            then
              echo "Installing Helm..."
              curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
            fi

            # Add ingress-nginx repo
            helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx || true
            helm repo update

            # Apply ingress-nginx
            helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
              --namespace ingress-nginx --create-namespace \
              -f helm/ingress-nginx/values-prod.yaml
          
            # Install or Upgrade Prometheus
            helm upgrade --install monitoring prometheus-community/kube-prometheus-stack \
              -n monitoring --create-namespace \
              -f helm/prometheus/values-prod.yaml
          
            # --- Prometheus Installation end ---

            # Create namespaces
            kubectl create namespace ${{ secrets.ENVIRONMENT }} --dry-run=client -o yaml | kubectl apply -f -
          
            # Set the current context to the desired namespace
            kubectl config set-context --current --namespace=${{ secrets.ENVIRONMENT }}

            # Apply ConfigMaps
            # kubectl apply -f config/

            # Create secret dynamically
            kubectl create secret generic rabbitmq-secret \
              --from-literal=RABBITMQ_DEFAULT_USER=${{ secrets.RABBITMQ_DEFAULT_USER }} \
              --from-literal=RABBITMQ_DEFAULT_PASS=${{ secrets.RABBITMQ_DEFAULT_PASS }} \
              --from-literal=RABBITMQ_HOST=${{ secrets.RABBITMQ_HOST }} \
              --from-literal=RABBITMQ_PORT=${{ secrets.RABBITMQ_PORT }} \
              --dry-run=client -o yaml | kubectl apply -f -
            

            # Apply RabbitMQ
            kubectl apply -f rabbitmq/

            # Apply Services
            for service in services/*; do
              kubectl apply -f $service/
            done

            # Apply Ingresses
            kubectl apply -f ingress/
          
            # Delete the key once done
            rm -rf ~/.kube/config

            echo "All manifests applied successfully."
          EOF